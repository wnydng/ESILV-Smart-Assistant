{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T10:58:04.274436Z",
     "start_time": "2026-01-06T10:57:57.561524Z"
    }
   },
   "cell_type": "code",
   "source": "pip install numpy",
   "id": "bedbef238b5ddae1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.4.0-cp313-cp313-win_amd64.whl.metadata (6.6 kB)\n",
      "Using cached numpy-2.4.0-cp313-cp313-win_amd64.whl (12.3 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T10:59:44.822072Z",
     "start_time": "2026-01-06T10:59:41.913570Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.13.2-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from faiss-cpu) (2.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Using cached faiss_cpu-1.13.2-cp313-cp313-win_amd64.whl (18.9 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": "pip install faiss-cpu",
   "id": "649f85c58f16cbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:09:17.424872Z",
     "start_time": "2026-01-06T11:09:13.076434Z"
    }
   },
   "cell_type": "code",
   "source": "pip install --upgrade ollama",
   "id": "3fc39caa4f9a884a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\nacca\\documents\\esilv\\llm_and_genai\\depot\\esilv-smart-assistant\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Using cached ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: annotated-types, pydantic, ollama\n",
      "\n",
      "   ------------- -------------------------- 1/3 [pydantic]\n",
      "   ------------- -------------------------- 1/3 [pydantic]\n",
      "   ------------- -------------------------- 1/3 [pydantic]\n",
      "   ------------- -------------------------- 1/3 [pydantic]\n",
      "   ------------- -------------------------- 1/3 [pydantic]\n",
      "   ------------- -------------------------- 1/3 [pydantic]\n",
      "   -------------------------- ------------- 2/3 [ollama]\n",
      "   ---------------------------------------- 3/3 [ollama]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 ollama-0.6.1 pydantic-2.12.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-06T11:30:24.073279Z",
     "start_time": "2026-01-06T11:30:22.945338Z"
    }
   },
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import ollama\n",
    "from ollama import Client"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:30:25.409968Z",
     "start_time": "2026-01-06T11:30:24.843946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHUNKS_DIR = os.path.abspath(\"../../data/chunks_esilv\")\n",
    "BASE_V2_DIR = os.path.abspath(\"../embeddings/vector_store_v2\")\n",
    "os.makedirs(BASE_V2_DIR, exist_ok=True)\n",
    "\n",
    "INDEX_PATH = os.path.join(BASE_V2_DIR, \"faiss_index.bin\")\n",
    "MAPPING_PATH = os.path.join(BASE_V2_DIR, \"mapping.json\")\n",
    "\n",
    "EMBED_DIM = 1024\n",
    "MODEL = \"mxbai-embed-large\"\n",
    "\n",
    "client = Client()"
   ],
   "id": "8cbfee5a72cdd8a8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:30:26.984919Z",
     "start_time": "2026-01-06T11:30:26.974590Z"
    }
   },
   "cell_type": "code",
   "source": "os.listdir(\"../../data/chunks_esilv\")",
   "id": "9fc0d318bfb7d22e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chunks_admissions.json',\n",
       " 'chunks_entreprises-debouches.json',\n",
       " 'chunks_formations.json',\n",
       " 'chunks_international.json',\n",
       " 'chunks_lecole.json',\n",
       " 'chunks_recherche.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:30:28.226863Z",
     "start_time": "2026-01-06T11:30:28.217726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Ollama client\n",
    "# -----------------------------\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: call Ollama + extract vector\n",
    "# -----------------------------\n",
    "def get_embedding_vector(resp) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Supporte:\n",
    "    - client.embed(...) -> EmbedResponse avec .embeddings (liste)\n",
    "    - client.embeddings(...) -> dict avec \"embedding\" OU \"embeddings\"\n",
    "    \"\"\"\n",
    "    # Case 1: pydantic object from client.embed()\n",
    "    if hasattr(resp, \"embeddings\"):\n",
    "        emb = resp.embeddings\n",
    "        if isinstance(emb, list) and len(emb) > 0:\n",
    "            # emb peut etre: [[...]] ou [...]\n",
    "            if isinstance(emb[0], list):\n",
    "                return np.array(emb[0], dtype=\"float32\")\n",
    "            return np.array(emb, dtype=\"float32\")\n",
    "\n",
    "    # Case 2: dict response\n",
    "    if isinstance(resp, dict):\n",
    "        if \"embedding\" in resp:\n",
    "            return np.array(resp[\"embedding\"], dtype=\"float32\")\n",
    "        if \"embeddings\" in resp and resp[\"embeddings\"]:\n",
    "            return np.array(resp[\"embeddings\"][0], dtype=\"float32\")\n",
    "\n",
    "    raise ValueError(f\"Unknown embedding response format: {type(resp)}\")\n",
    "\n",
    "def embed_once(text: str) -> np.ndarray:\n",
    "    # API moderne si dispo\n",
    "    if hasattr(client, \"embed\"):\n",
    "        resp = client.embed(model=MODEL, input=text)\n",
    "    else:\n",
    "        resp = client.embeddings(model=MODEL, prompt=text)\n",
    "\n",
    "    v = get_embedding_vector(resp)\n",
    "\n",
    "    # normalize for cosine-like retrieval with IndexFlatIP\n",
    "    v /= (np.linalg.norm(v) + 1e-12)\n",
    "    return v"
   ],
   "id": "fc5b911c0ff1f203",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:30:30.607027Z",
     "start_time": "2026-01-06T11:30:30.597079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Chunking safe for context length\n",
    "# -----------------------------\n",
    "MAX_CHARS_PER_PART = 1200  # petit => evite overflow tokens\n",
    "\n",
    "def split_text(text: str, max_chars: int):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "\n",
    "def embed_text_full(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Zero perte d'info: on embed TOUT le texte via morceaux,\n",
    "    puis on moyenne les embeddings.\n",
    "    \"\"\"\n",
    "    parts = split_text(text, MAX_CHARS_PER_PART)\n",
    "    if not parts:\n",
    "        raise ValueError(\"Empty text after stripping\")\n",
    "\n",
    "    vecs = []\n",
    "    for p in parts:\n",
    "        resp = ollama_embed(\"mxbai-embed-large\", p)\n",
    "\n",
    "        # Depending on API, field can be \"embeddings\" or \"embedding\"\n",
    "        if isinstance(resp, dict) and \"embedding\" in resp:\n",
    "            v = np.array(resp[\"embedding\"], dtype=\"float32\")\n",
    "        elif isinstance(resp, dict) and \"embeddings\" in resp:\n",
    "            # Some clients return list of embeddings\n",
    "            v = np.array(resp[\"embeddings\"][0], dtype=\"float32\")\n",
    "        else:\n",
    "            # Last resort: try attribute-like access (rare)\n",
    "            v = np.array(resp.embedding, dtype=\"float32\")\n",
    "\n",
    "        vecs.append(v)\n",
    "\n",
    "    v_mean = np.mean(np.stack(vecs, axis=0), axis=0).astype(\"float32\")\n",
    "\n",
    "    # Normalize for cosine-like retrieval with IndexFlatIP\n",
    "    v_mean /= (np.linalg.norm(v_mean) + 1e-12)\n"
   ],
   "id": "f43289ecd3fd1bc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:30:35.951986Z",
     "start_time": "2026-01-06T11:30:35.943433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Split to avoid context overflow\n",
    "# -----------------------------\n",
    "MAX_CHARS_PER_PART = 1200\n",
    "\n",
    "def split_text(text: str, max_chars: int):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "\n",
    "def embed_text_full(text: str) -> np.ndarray:\n",
    "    parts = split_text(text, MAX_CHARS_PER_PART)\n",
    "    if not parts:\n",
    "        raise ValueError(\"Empty text\")\n",
    "\n",
    "    vecs = [embed_once(p) for p in parts]\n",
    "    v_mean = np.mean(np.stack(vecs, axis=0), axis=0).astype(\"float32\")\n",
    "    v_mean /= (np.linalg.norm(v_mean) + 1e-12)\n",
    "    return v_mean"
   ],
   "id": "fed275d7c4de6e7e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:38:12.679967Z",
     "start_time": "2026-01-06T11:30:38.725076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Build FAISS v2\n",
    "# -----------------------------\n",
    "index = faiss.IndexFlatIP(EMBED_DIM)\n",
    "mapping = {}\n",
    "added = 0\n",
    "\n",
    "for fn in sorted(os.listdir(CHUNKS_DIR)):\n",
    "    if not fn.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(CHUNKS_DIR, fn)\n",
    "    print(\"Traitement:\", fn)\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        content = (chunk.get(\"content\") or \"\").strip()\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        title = (chunk.get(\"title\") or \"\").strip()\n",
    "        rubric = (chunk.get(\"rubric\") or \"\").strip()\n",
    "        url = chunk.get(\"url\")\n",
    "\n",
    "        embed_input = f\"TITLE: {title}\\nRUBRIC: {rubric}\\nCONTENT:\\n{content}\"\n",
    "\n",
    "        v = embed_text_full(embed_input).reshape(1, -1)\n",
    "\n",
    "        idx_id = index.ntotal\n",
    "        index.add(v)\n",
    "\n",
    "        mapping[str(idx_id)] = {\n",
    "            \"title\": title,\n",
    "            \"content\": content,  # on conserve TOUT\n",
    "            \"rubric\": rubric,\n",
    "            \"url\": url,\n",
    "            \"source_file\": fn,\n",
    "            \"embedding_input_chars\": len(embed_input),\n",
    "            \"parts_count\": int(np.ceil(len(embed_input) / MAX_CHARS_PER_PART)),\n",
    "            \"max_chars_per_part\": MAX_CHARS_PER_PART,\n",
    "        }\n",
    "\n",
    "        added += 1"
   ],
   "id": "380dbad525971c6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement: chunks_admissions.json\n",
      "Traitement: chunks_entreprises-debouches.json\n",
      "Traitement: chunks_formations.json\n",
      "Traitement: chunks_international.json\n",
      "Traitement: chunks_lecole.json\n",
      "Traitement: chunks_recherche.json\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T11:38:20.777027Z",
     "start_time": "2026-01-06T11:38:20.758888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Vectors added:\", added)\n",
    "print(\"Index total:\", index.ntotal)\n",
    "\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "with open(MAPPING_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mapping, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved index:\", INDEX_PATH)\n",
    "print(\"Saved mapping:\", MAPPING_PATH)"
   ],
   "id": "73d1ce337e47d141",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors added: 533\n",
      "Index total: 533\n",
      "Saved index: C:\\Users\\nacca\\Documents\\ESILV\\LLM_and_GENAI\\DEPOT\\ESILV-Smart-Assistant\\code\\embeddings\\vector_store_v2\\faiss_index.bin\n",
      "Saved mapping: C:\\Users\\nacca\\Documents\\ESILV\\LLM_and_GENAI\\DEPOT\\ESILV-Smart-Assistant\\code\\embeddings\\vector_store_v2\\mapping.json\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
